{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalación de requerimientos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga y preprocesamiento de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scripts.preprocessing import load_data, preprocess_data\n",
    "\n",
    "train_path = 'data/ECG5000_train.csv'\n",
    "test_path = 'data/ECG5000_test.csv'\n",
    "\n",
    "train_data, test_data = load_data(train_path, test_path) #carga de datos\n",
    "\n",
    "x_train_scaled, x_test_scaled, scaler = preprocess_data(train_data, test_data) #se escalan los datros de entrenamiento y prueba y se guarda el escalador (MinMaxScaler())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualización de muestras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.visualization import plot_ecg_samples\n",
    "\n",
    "x_train_descaled = scaler.inverse_transform(x_train_scaled)\n",
    "x_test_descaled = scaler.inverse_transform(x_test_scaled)\n",
    "\n",
    "# Sin escalar\n",
    "plot_ecg_samples(x_train_descaled[train_data[0] == 1],\n",
    "                 x_train_descaled[train_data[0] == 2],\n",
    "                 x_train_descaled[train_data[0] == 3],\n",
    "                 x_train_descaled[train_data[0] == 4],\n",
    "                 x_train_descaled[train_data[0] == 5],\n",
    "                 ind=7)\n",
    "\n",
    "# Escalados\n",
    "# plot_ecg_samples(x_train_scaled[train_data[0] == 1],\n",
    "#                  x_train_scaled[train_data[0] == 2],\n",
    "#                  x_train_scaled[train_data[0] == 3],\n",
    "#                  x_train_scaled[train_data[0] == 4],\n",
    "#                  x_train_scaled[train_data[0] == 5],\n",
    "#                  ind=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento del autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.model import build_autoencoder, compile_and_train\n",
    "\n",
    "# Constructor\n",
    "input_dim = x_train_scaled[train_data[0] == 1].shape[1] #SOlo tomamos los datos de entrenamiento de la catagorìa '0' (normales)\n",
    "autoencoder = build_autoencoder(input_dim)\n",
    "\n",
    "# Entrenamiento del autoencoder\n",
    "historia = compile_and_train(autoencoder, x_train_scaled[train_data[0] == 1], x_test_scaled[test_data[0] == 1], epochs=30, batch_size=512) \n",
    "\n",
    "autoencoder.save_weights('models/autoencoder_weights.weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizaciones de historia y summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.visualization import plot_training_history\n",
    "# Es necesario haber corrido el bloque anterio para obtener \"historia\" y \"autoencoder\"\n",
    "plot_training_history(historia) \n",
    "\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualización de reconstrucciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.model import build_autoencoder\n",
    "from scripts.visualization import plot_ecg_reconstruction\n",
    "\n",
    "# Constructor del autoencoder\n",
    "input_dim = x_train_scaled.shape[1]\n",
    "autoencoder = build_autoencoder(input_dim)\n",
    "\n",
    "# Carga de los pesos\n",
    "autoencoder.load_weights('models/autoencoder_weights.weights.h5')\n",
    "\n",
    "x_test_1_s = x_test_scaled[test_data[0] == 1]\n",
    "x_test_2_s = x_test_scaled[test_data[0] == 2]\n",
    "x_test_3_s = x_test_scaled[test_data[0] == 3]\n",
    "x_test_4_s = x_test_scaled[test_data[0] == 4]\n",
    "x_test_5_s = x_test_scaled[test_data[0] == 5]\n",
    "\n",
    "plot_ecg_reconstruction(autoencoder, x_test_1_s, x_test_5_s, index=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualización de histograma de distribución\n",
    "\n",
    "En el siguiente gráfico se muestra la distribución de la función de pérdida al reconstruir (.predict) ECG normales y los 4 tipos de anormales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.visualization import load_autoencoder_weights, calculate_losses, plot_loss_histograms\n",
    "from scripts.model import build_autoencoder\n",
    "\n",
    "# Construir el autoencoder y cargar los pesos\n",
    "input_dim = x_train_scaled.shape[1] \n",
    "autoencoder = build_autoencoder(input_dim)\n",
    "autoencoder = load_autoencoder_weights(autoencoder, 'models/autoencoder_weights.weights.h5')\n",
    "\n",
    "# Calculo de pérdidas\n",
    "losses = calculate_losses(autoencoder, [x_test_1_s, x_test_2_s, x_test_3_s, x_test_4_s, x_test_5_s])\n",
    "\n",
    "plot_loss_histograms(losses, threshold=0.08)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.visualization import load_autoencoder_weights, calculate_losses, plot_loss_histograms\n",
    "from scripts.model import build_autoencoder\n",
    "from scripts.evaluation import calculate_threshold, predict, calculate_sensitivity, calculate_specificity\n",
    "\n",
    "# Construir el autoencoder y cargar los pesos\n",
    "input_dim = x_train_scaled.shape[1]\n",
    "autoencoder = build_autoencoder(input_dim)\n",
    "autoencoder = load_autoencoder_weights(autoencoder, 'models/autoencoder_weights.weights.h5')\n",
    "\n",
    "# Calculo las pérdidas\n",
    "losses = calculate_losses(autoencoder, [x_test_1_s, x_test_2_s, x_test_3_s, x_test_4_s, x_test_5_s])\n",
    "\n",
    "#threshold = calculate_threshold(losses[0])\n",
    "threshold = 0.011\n",
    "\n",
    "print(f\"El umbral calculado es: {threshold}\")\n",
    "\n",
    "# Predicciones\n",
    "preds = [predict(autoencoder, x_test, threshold) for x_test in [x_test_1_s, x_test_2_s, x_test_3_s, x_test_4_s, x_test_5_s]]\n",
    "\n",
    "# CON RESPECTO A LAS MÉTRICAS, SE UTILIZAN LAS SIGUIENTES TENIENDO EN CUENTA QUE AL SER PREDICCION DE ANOMALIAS CARDIACAS,\n",
    "# ES MAS IMPORTANTE OBTENER BUENA SENSIBILIDAD, ES DECIR QUE OPTIMICE EL RECONOCIMIENTO DE CASOS ANORMALES A COSTA DE CLASIFICAR ERRONEAMENTE CASOS\n",
    "# NORMALES COMO ANORMALES\n",
    "\n",
    "\n",
    "esp_1 = calculate_specificity(preds[0], 'Especificidad (cat. 1, normales)')\n",
    "sensitivities = [calculate_sensitivity(preds[i], f'Sensitividad (cat. {i+2}, anormales)') for i in range(1, 5)]\n",
    "\n",
    "plot_loss_histograms(losses, threshold=threshold)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
